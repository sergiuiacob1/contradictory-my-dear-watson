{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"0\" # to silence warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n",
    "    print('Number of replicas:', strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape # check data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape # check data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.vocab) # check the vocabulary size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "    \"\"\" ENCODE SENTENCES WITH TOKENIZER\"\"\"\n",
    "    tokens = list(tokenizer.tokenize(s))\n",
    "    tokens.append('[SEP]')\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_sentence(\"you know they can't really defend themselves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(hypotheses, premises, tokenizer):\n",
    "    \"\"\" ENCODE DATA FOR BERT\"\"\"\n",
    "    num_examples = len(hypotheses)\n",
    "    print(\"num_examples = \", num_examples)\n",
    "    sentence1 = tf.ragged.constant([encode_sentence(s) for s in np.array(hypotheses)])\n",
    "    print(\"sentence1.shape = \", sentence1.shape)\n",
    "    sentence2 = tf.ragged.constant([encode_sentence(s) for s in np.array(premises)])\n",
    "    print(\"sentence2.shape = \", sentence2.shape)\n",
    "    cls_ = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * sentence1.shape[0]\n",
    "    input_word_ids = tf.concat([cls_, sentence1, sentence2], axis=-1)\n",
    "    print(\"input_word_ids.shape = \", input_word_ids.shape)\n",
    "    # 300 - as my example\n",
    "    # because we have train_input (12120; 259), test_input (5159; 234)\n",
    "    # and shape[1] should be the same in each dataset\n",
    "    # that is why we creating (xxx; 300) shape in to_tensor() functions  \n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(input_word_ids.shape[0], 300)) \n",
    "    print(\"input_mask.shape = \", input_mask.shape)\n",
    "    \n",
    "    type_cls = tf.zeros_like(cls_)\n",
    "    type_s1 = tf.zeros_like(sentence1)\n",
    "    type_s2 = tf.ones_like(sentence2)\n",
    "    \n",
    "    input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor(shape=(input_word_ids.shape[0], 300))\n",
    "    \n",
    "    inputs = {'input_word_ids': input_word_ids.to_tensor(shape=(input_word_ids.shape[0], 300)),\n",
    "              'input_mask': input_mask,\n",
    "              'input_type_ids': input_type_ids}\n",
    "    print()\n",
    "    \n",
    "    return inputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data\n",
    "train_input = bert_encode(df_train[\"premise\"].values, df_train[\"hypothesis\"].values, tokenizer)\n",
    "test_input = bert_encode(df_test[\"premise\"].values, df_test[\"hypothesis\"].values, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input # check train input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input # check test input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = train_input[\"input_word_ids\"].shape[1]\n",
    "\n",
    "def create_model():\n",
    "    \"\"\" BUILD MODEL \"\"\"\n",
    "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_input, \n",
    "                          df_train[\"label\"].values, \n",
    "                          epochs = 3, \n",
    "                          verbose = 1,\n",
    "                          batch_size = 128, \n",
    "                          validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_NN_history(model_history, suptitle):\n",
    "    # plot data\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "    fig.suptitle(suptitle, fontsize=18)\n",
    "    \n",
    "    axes[0].plot(model_history.history['accuracy'], label='train accuracy', color='g', axes=axes[0])\n",
    "    axes[0].plot(model_history.history['val_accuracy'], label='val accuracy', color='r', axes=axes[0])\n",
    "    axes[0].set_title(\"Model Accuracy\", fontsize=16) \n",
    "    axes[0].legend(loc='upper left')\n",
    "\n",
    "    axes[1].plot(model_history.history['loss'], label='train loss', color='g', axes=axes[1])\n",
    "    axes[1].plot(model_history.history['val_loss'], label='val loss', color='r', axes=axes[1])\n",
    "    axes[1].set_title(\"Model Loss\", fontsize=16) \n",
    "    axes[1].legend(loc='upper left')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_NN_history(model_history, \"BERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\" CALCULATE RESULTS\"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                     \"precision\": model_precision,\n",
    "                     \"recall\": model_recall,\n",
    "                     \"f1\": model_f1}\n",
    "    return model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probabilities\n",
    "y_prob = model.predict(test_input)\n",
    "# get the classes\n",
    "y_hat = y_prob.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = df_test.id.copy().to_frame()\n",
    "# submission['prediction'] = y_hat\n",
    "# submission.head() # check submission\n",
    "# submission.to_csv(\"submission.csv\", index = False) # save file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
